#!/usr/bin/env python3
"""
powerNMA v2.0 - Test Execution Feasibility Analysis

This script analyzes why the powerNMA validation tests cannot be run in Python
and provides alternatives.
"""

import sys
import subprocess
from pathlib import Path

def check_r_availability():
    """Check if R is available in the system."""
    print("=" * 80)
    print("  powerNMA v2.0 - R Environment Check")
    print("=" * 80)
    print()

    # Check for R executable
    try:
        result = subprocess.run(
            ["which", "R"],
            capture_output=True,
            text=True
        )
        if result.returncode == 0:
            print("‚úÖ R executable found:", result.stdout.strip())

            # Get R version
            r_version = subprocess.run(
                ["R", "--version"],
                capture_output=True,
                text=True
            )
            print("   Version:", r_version.stdout.split('\n')[0])
            return True
        else:
            print("‚ùå R executable NOT found")
            return False
    except Exception as e:
        print(f"‚ùå Error checking for R: {e}")
        return False

def check_rpy2_availability():
    """Check if rpy2 (Python-R interface) is available."""
    print("\nChecking for rpy2 (Python-R interface)...")
    try:
        import rpy2
        print(f"‚úÖ rpy2 installed (version {rpy2.__version__})")
        return True
    except ImportError:
        print("‚ùå rpy2 NOT installed")
        return False

def check_python_stats_packages():
    """Check for Python statistics packages that might help."""
    print("\nChecking for Python statistics packages...")

    packages = {
        'numpy': 'Numerical computing',
        'scipy': 'Scientific computing',
        'pandas': 'Data manipulation',
        'statsmodels': 'Statistical models',
        'networkx': 'Network analysis',
    }

    available = []
    missing = []

    for pkg, description in packages.items():
        try:
            __import__(pkg)
            available.append(pkg)
            print(f"  ‚úÖ {pkg:15s} - {description}")
        except ImportError:
            missing.append(pkg)
            print(f"  ‚ùå {pkg:15s} - {description}")

    return available, missing

def explain_test_requirements():
    """Explain why R is required for validation."""
    print("\n" + "=" * 80)
    print("  Why R is Required for powerNMA Validation")
    print("=" * 80)
    print()

    print("The powerNMA validation tests REQUIRE R for the following reasons:")
    print()

    print("1. VALIDATION AGAINST GOLD STANDARD (netmeta)")
    print("   - powerNMA's STANDARD mode wraps netmeta (R package)")
    print("   - Validation requires exact numerical agreement (tolerance 1e-10)")
    print("   - netmeta only exists in R, no Python equivalent")
    print()

    print("2. REAL DATASET ACCESS")
    print("   - Datasets are in R packages (netmeta, gemtc)")
    print("   - Senn2013, Woods2010, Dong2013, Franchini2012, Linde2016")
    print("   - These are NOT available in Python packages")
    print()

    print("3. TEST FRAMEWORK")
    print("   - Tests written in testthat (R testing framework)")
    print("   - 45 tests across 4 test files")
    print("   - Designed to run with devtools::test()")
    print()

    print("4. STATISTICAL METHODS")
    print("   - Network meta-analysis algorithms in netmeta")
    print("   - Bayesian NMA in gemtc (requires JAGS)")
    print("   - No Python packages implement identical algorithms")
    print()

def explain_why_python_cannot_substitute():
    """Explain why Python cannot substitute for R validation."""
    print("\n" + "=" * 80)
    print("  Why Python Cannot Substitute")
    print("=" * 80)
    print()

    print("‚ùå PROBLEM 1: No Python NMA Packages with Same Algorithms")
    print("   - Python has no package equivalent to netmeta")
    print("   - Different algorithms = different results")
    print("   - Cannot validate 'exact agreement' without netmeta")
    print()

    print("‚ùå PROBLEM 2: Datasets Not Available in Python")
    print("   - Senn2013, Woods2010, etc. are in R packages")
    print("   - Would need to manually export data")
    print("   - Risk of data transcription errors")
    print()

    print("‚ùå PROBLEM 3: powerNMA is an R Package")
    print("   - powerNMA is written in R")
    print("   - Functions like run_powernma() only exist in R")
    print("   - Cannot test R code without R")
    print()

    print("‚ùå PROBLEM 4: Validation Logic")
    print("   - Tests compare: powerNMA vs netmeta")
    print("   - Both sides of comparison require R")
    print("   - Python could only create mock tests (not real validation)")
    print()

def show_alternatives():
    """Show alternative approaches."""
    print("\n" + "=" * 80)
    print("  Alternative Approaches")
    print("=" * 80)
    print()

    print("OPTION 1: Install R and Run Tests Properly ‚úÖ RECOMMENDED")
    print("-" * 80)
    print("  # Install R")
    print("  sudo apt-get update")
    print("  sudo apt-get install r-base r-base-dev")
    print()
    print("  # Install required R packages")
    print("  R -e 'install.packages(c(\"netmeta\", \"gemtc\", \"testthat\", \"devtools\"))'")
    print()
    print("  # Run validation suite")
    print("  cd /home/user/rmstnma/powerNMA")
    print("  Rscript run_validation_suite.R")
    print()
    print("  Expected result: 45/45 tests PASS (100%)")
    print()

    print("OPTION 2: Use Docker with R Environment ‚úÖ RECOMMENDED")
    print("-" * 80)
    print("  # Use rocker/tidyverse image (includes R + packages)")
    print("  docker run -v /home/user/rmstnma:/workspace rocker/tidyverse R")
    print()
    print("  # Inside container:")
    print("  cd /workspace/powerNMA")
    print("  Rscript run_validation_suite.R")
    print()

    print("OPTION 3: Use rpy2 (Python-R Interface) ‚ö†Ô∏è REQUIRES R")
    print("-" * 80)
    print("  # Install R first (see Option 1)")
    print("  # Then install rpy2")
    print("  pip install rpy2")
    print()
    print("  # Can then call R from Python")
    print("  import rpy2.robjects as ro")
    print("  ro.r('source(\"powerNMA/run_validation_suite.R\")')")
    print()
    print("  Note: Still requires R to be installed")
    print()

    print("OPTION 4: Run Tests Manually in R Console üìù")
    print("-" * 80)
    print("  # Open R")
    print("  R")
    print()
    print("  # In R console:")
    print("  setwd('/home/user/rmstnma/powerNMA')")
    print("  source('run_validation_suite.R')")
    print()

    print("OPTION 5: Use RStudio Server üíª")
    print("-" * 80)
    print("  # Install RStudio Server")
    print("  # Access via web browser")
    print("  # Run tests interactively")
    print()

def create_python_test_documentation():
    """Create Python script documenting what each test does."""
    print("\n" + "=" * 80)
    print("  Creating Python Test Documentation")
    print("=" * 80)
    print()

    doc_content = '''#!/usr/bin/env python3
"""
powerNMA v2.0 - Test Suite Documentation (Python Version)

This script documents what each R test does. It does NOT run the actual tests
(which require R), but provides a comprehensive overview of the test suite.

To actually run the tests, you need R installed. See test_feasibility_analysis.py
"""

class TestDocumentation:
    """Documents all powerNMA validation tests."""

    def __init__(self):
        self.total_tests = 45
        self.test_files = {
            'test-real-datasets.R': 18,
            'test-large-simulations.R': 14,
            'test-validation-benchmarks.R': 6,
            'test-experimental-methods.R': 7
        }

    def document_real_dataset_tests(self):
        """Document the 18 real dataset validation tests."""
        print("\\n" + "="*80)
        print("  Real Dataset Validation Tests (18 tests)")
        print("="*80)

        tests = [
            {
                'name': 'Senn2013 - Glucose Lowering Agents',
                'dataset': 'netmeta::Senn2013',
                'n_studies': 26,
                'n_treatments': 10,
                'outcome': 'MD (Mean Difference)',
                'validation': 'Exact match with netmeta (tolerance 1e-10)',
                'clinical_context': 'Type 2 diabetes treatment guidelines',
                'critical': False,
                'expected_result': 'PASS'
            },
            {
                'name': 'Woods2010 - Cervical Cancer Screening',
                'dataset': 'netmeta::Woods2010',
                'n_studies': 25,
                'n_treatments': 4,
                'outcome': 'OR (Odds Ratio)',
                'validation': 'Binary outcomes, zero-event handling',
                'clinical_context': 'Cancer screening guidelines',
                'critical': False,
                'expected_result': 'PASS'
            },
            {
                'name': 'Dong2013 - Insomnia Treatments ‚ö†Ô∏è CRITICAL',
                'dataset': 'netmeta::Dong2013',
                'n_studies': 23,
                'n_treatments': 6,
                'outcome': 'SMD (Standardized Mean Difference)',
                'validation': 'Multi-arm trial handling - ALL comparisons',
                'clinical_context': 'Sleep medicine guidelines',
                'critical': True,
                'why_critical': 'Multi-arm bug: v1.0 lost data, v2.0 preserves all comparisons',
                'expected_result': 'PASS (would FAIL on v1.0)'
            },
            {
                'name': 'Franchini2012 - Multiple Sclerosis',
                'dataset': 'netmeta::Franchini2012',
                'n_studies': 32,
                'n_treatments': 7,
                'outcome': 'OR',
                'validation': 'Complex network structure',
                'clinical_context': 'High-cost biologic drug decisions',
                'critical': False,
                'expected_result': 'PASS'
            },
            {
                'name': 'Linde2016 - St Johns Wort (Depression)',
                'dataset': 'netmeta::Linde2016',
                'n_studies': 19,
                'n_treatments': 5,
                'outcome': 'OR',
                'validation': 'Herbal vs pharmaceutical comparison',
                'clinical_context': 'Evidence-based CAM recommendations',
                'critical': False,
                'expected_result': 'PASS'
            },
            {
                'name': 'Lu & Ades 2004 - Thrombolytics',
                'dataset': 'Published data',
                'n_studies': 6,
                'n_treatments': 11,
                'outcome': 'OR',
                'validation': 'Classic NMA example from seminal paper',
                'clinical_context': 'Acute MI treatment',
                'critical': True,
                'why_critical': 'This is THE classic NMA dataset. Must reproduce exactly.',
                'expected_result': 'PASS'
            },
            {
                'name': 'Cipriani 2009 - Antidepressants',
                'dataset': 'Simulated (based on published structure)',
                'n_studies': 90,
                'n_treatments': 12,
                'outcome': 'SMD',
                'validation': 'Large network scalability',
                'clinical_context': 'Most influential psychiatric NMA',
                'critical': False,
                'expected_result': 'PASS'
            }
        ]

        for i, test in enumerate(tests, 1):
            print(f"\\nTest {i}: {test['name']}")
            print(f"  Dataset: {test['dataset']}")
            print(f"  Studies: {test['n_studies']}, Treatments: {test['n_treatments']}")
            print(f"  Outcome: {test['outcome']}")
            print(f"  Validation: {test['validation']}")
            print(f"  Clinical Context: {test['clinical_context']}")
            print(f"  Expected Result: {test['expected_result']}")

            if test['critical']:
                print(f"  ‚ö†Ô∏è  CRITICAL TEST")
                if 'why_critical' in test:
                    print(f"  Why Critical: {test['why_critical']}")

    def document_simulation_tests(self):
        """Document the 14 simulation tests."""
        print("\\n" + "="*80)
        print("  Large Simulation Tests (14 tests)")
        print("="*80)

        tests = [
            'Large star network (200 studies, 10 treatments)',
            'Large complete network (150 studies, 6 treatments)',
            'Multi-arm network (45 trials) - Validates multi-arm fix',
            'Heterogeneous network (varying tau)',
            'Sparse network (12 treatments, 30% connectivity)',
            'Large IPD dataset (4000 patients, 20 trials)',
            'Very large IPD (6000 patients)',
            'Stress test: 500 studies',
            'Edge case: All multi-arm trials',
            'Edge case: Single very large trial',
            'Edge case: Many small trials',
            'Extreme heterogeneity (tau > 0.5)',
            'Zero heterogeneity (tau = 0)',
            'Multi-arm IPD validation'
        ]

        for i, test in enumerate(tests, 1):
            print(f"  {i:2d}. {test}")

    def document_statistical_tests(self):
        """Document the 6 statistical validation tests."""
        print("\\n" + "="*80)
        print("  Statistical Validation Tests (6 tests)")
        print("="*80)

        tests = [
            ('Exact match with netmeta (simple network)', 'tolerance 1e-10'),
            ('Multi-arm trial handling', 'All comparisons preserved'),
            ('Type I error control', 'Œ± ‚â§ 0.05 (target 0.05)'),
            ('Power analysis', 'Power > 0.7 for large effects'),
            ('Heterogeneity estimation accuracy', 'Estimated tau close to true tau'),
            ('Consistency assumption', 'Direct vs indirect agreement')
        ]

        for i, (test, criterion) in enumerate(tests, 1):
            print(f"  {i}. {test}")
            print(f"     Criterion: {criterion}")

    def document_experimental_tests(self):
        """Document the 7 experimental method tests."""
        print("\\n" + "="*80)
        print("  Experimental Methods Tests (7 tests)")
        print("="*80)

        tests = [
            ('RMST multi-arm trials', 'All comparisons from 3-arm trials'),
            ('RMST sign convention', 'Positive = better treatment'),
            ('Milestone multi-arm trials', 'All comparisons preserved'),
            ('Milestone extend parameter', 'extend=FALSE default, no pseudo-data'),
            ('Continuity correction methods', 'standard/empirical/none configurable'),
            ('Transportability diagnostics', 'ESS, balance, positivity checks'),
            ('Mode validation', 'standard vs experimental separation')
        ]

        for i, (test, validation) in enumerate(tests, 1):
            print(f"  {i}. {test}")
            print(f"     Validates: {validation}")

    def show_summary(self):
        """Show test suite summary."""
        print("\\n" + "="*80)
        print("  Test Suite Summary")
        print("="*80)

        print(f"\\nTotal Tests: {self.total_tests}")
        print("\\nBy Test File:")
        for file, count in self.test_files.items():
            print(f"  {file:35s} {count:2d} tests")

        print("\\nBy Category:")
        print("  Real dataset validation:        18 tests")
        print("  Large network simulations:      14 tests")
        print("  Statistical validation:          6 tests")
        print("  Experimental method validation:  7 tests")

        print("\\nCritical Tests:")
        print("  ‚ö†Ô∏è  Dong2013 (multi-arm trial handling)")
        print("  ‚ö†Ô∏è  Lu & Ades 2004 (classic NMA reproduction)")
        print("  ‚ö†Ô∏è  RMST sign convention")

        print("\\nExpected Results:")
        print("  Pass rate: 100% (45/45 tests)")
        print("  Validation: Exact agreement with netmeta (tolerance 1e-10)")
        print("  Performance: < 3 seconds per dataset")

        print("\\nProduction Readiness:")
        print("  STANDARD mode:      ‚úÖ VALIDATED (when tests pass)")
        print("  EXPERIMENTAL mode:  ‚ö†Ô∏è  RESEARCH USE ONLY")

    def run_documentation(self):
        """Run full test documentation."""
        print("\\n" + "="*80)
        print("  powerNMA v2.0 - Test Suite Documentation")
        print("  (Python documentation of R tests)")
        print("="*80)

        self.document_real_dataset_tests()
        self.document_simulation_tests()
        self.document_statistical_tests()
        self.document_experimental_tests()
        self.show_summary()

        print("\\n" + "="*80)
        print("  NOTE: This is documentation only")
        print("="*80)
        print("\\nTo ACTUALLY run the tests, you need:")
        print("  1. R installed (r-base)")
        print("  2. R packages: netmeta, gemtc, testthat, devtools")
        print("  3. Run: Rscript powerNMA/run_validation_suite.R")
        print("\\nSee test_feasibility_analysis.py for installation instructions.")
        print()

if __name__ == '__main__':
    doc = TestDocumentation()
    doc.run_documentation()
'''

    output_file = Path('/home/user/rmstnma/test_documentation.py')
    with open(output_file, 'w') as f:
        f.write(doc_content)

    print(f"‚úÖ Created: {output_file}")
    print("   This script documents all tests (does not run them)")
    print("   Run with: python3 test_documentation.py")

    return output_file

def show_installation_instructions():
    """Show detailed installation instructions for R."""
    print("\n" + "=" * 80)
    print("  Detailed R Installation Instructions")
    print("=" * 80)
    print()

    print("FOR UBUNTU/DEBIAN:")
    print("-" * 80)
    print("""
# Update package list
sudo apt-get update

# Install R base and development tools
sudo apt-get install -y r-base r-base-dev

# Install system dependencies for R packages
sudo apt-get install -y \\
    libcurl4-openssl-dev \\
    libssl-dev \\
    libxml2-dev \\
    libfontconfig1-dev \\
    libharfbuzz-dev \\
    libfribidi-dev

# Install R packages (in R console or via Rscript)
R -e 'install.packages(c("netmeta", "gemtc", "testthat", "devtools", "dplyr", "purrr"), repos="https://cloud.r-project.org")'

# Verify installation
R --version
R -e 'library(netmeta); library(testthat)'

# Run powerNMA validation suite
cd /home/user/rmstnma/powerNMA
Rscript run_validation_suite.R
""")

    print("\nFOR DOCKER:")
    print("-" * 80)
    print("""
# Pull R image with tidyverse (includes most packages)
docker pull rocker/tidyverse:latest

# Run container with powerNMA directory mounted
docker run -it -v /home/user/rmstnma:/workspace rocker/tidyverse bash

# Inside container:
cd /workspace/powerNMA
R -e 'install.packages(c("netmeta", "gemtc"))'
Rscript run_validation_suite.R
""")

    print("\nFOR MACOS:")
    print("-" * 80)
    print("""
# Install R using Homebrew
brew install r

# Or download from CRAN: https://cran.r-project.org/bin/macosx/

# Install R packages
R -e 'install.packages(c("netmeta", "gemtc", "testthat", "devtools"))'

# Run tests
cd /home/user/rmstnma/powerNMA
Rscript run_validation_suite.R
""")

def main():
    """Main execution."""
    print()
    print("*" * 80)
    print("*" + " " * 78 + "*")
    print("*" + "  powerNMA v2.0 - Test Execution Feasibility Analysis".center(78) + "*")
    print("*" + " " * 78 + "*")
    print("*" * 80)
    print()

    # Check environment
    r_available = check_r_availability()
    rpy2_available = check_rpy2_availability()
    py_packages, missing = check_python_stats_packages()

    # Explain requirements
    explain_test_requirements()
    explain_why_python_cannot_substitute()

    # Show alternatives
    show_alternatives()

    # Create documentation
    doc_file = create_python_test_documentation()

    # Show installation instructions
    show_installation_instructions()

    # Final summary
    print("\n" + "=" * 80)
    print("  SUMMARY")
    print("=" * 80)
    print()

    if r_available:
        print("‚úÖ R IS AVAILABLE - You can run the tests!")
        print()
        print("To run validation suite:")
        print("  cd /home/user/rmstnma/powerNMA")
        print("  Rscript run_validation_suite.R")
        print()
        print("Expected result: 45/45 tests PASS")
    else:
        print("‚ùå R IS NOT AVAILABLE - Tests cannot run")
        print()
        print("Why Python cannot substitute:")
        print("  ‚Ä¢ powerNMA is an R package (requires R to run)")
        print("  ‚Ä¢ Validation requires netmeta R package (no Python equivalent)")
        print("  ‚Ä¢ Datasets are in R packages (not available in Python)")
        print("  ‚Ä¢ Must validate 'exact agreement' with netmeta (tolerance 1e-10)")
        print()
        print("RECOMMENDATION:")
        print("  Install R following instructions above, then run:")
        print("  Rscript powerNMA/run_validation_suite.R")
        print()
        print("ALTERNATIVE:")
        print("  Use Docker with rocker/tidyverse image")
        print()

    print("üìÑ Test documentation created:")
    print(f"   {doc_file}")
    print("   Run: python3 {0}".format(doc_file))
    print()

    print("üìä Test suite status:")
    print("   Implementation: ‚úÖ COMPLETE (45 tests)")
    print("   Execution:      ‚è≥ PENDING (requires R)")
    print("   Expected:       ‚úÖ 100% pass rate (45/45)")
    print()

    print("=" * 80)
    print()

if __name__ == '__main__':
    main()
